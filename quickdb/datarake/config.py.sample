import subprocess
from functools import lru_cache
from typing import Any, Callable

from ..sspcatalog.patch import Patch, Rerun

###############################################################################
# master_addr
#
# Workers allow access from only `master_addr`
###############################################################################
master_addr = '133.40.210.189'  # socket.gethostbyname('quickdb-master.example.com')


###############################################################################
# workers
#
# Master scatters jobs over `workers`
###############################################################################
class Worker:
    def __init__(self, host, hostname, work_dir, python_path, port=2935):
        '''
        Holds settings for a worker node.

        Args:
            host (str): Host address used to connect
            hostname: Result of `hostname` command on the worker.
                      This will be used to determine `this_worker`
            work_dir: Work directory on the worker node.
                      Data directory will be placed here.
            python_path: Python binary path.
            port: Worker process will wait for a connection from master on this port.
        '''
        self.host = host
        self.hostname = hostname
        self.port = port
        self.work_dir = work_dir
        self.python_path = python_path


user = 'michitaro'
work_dir = f'/db1/koike/quickdb-pdr2'
python_path = f'/home/{user}/anaconda3/bin/python'

workers = [
    Worker('hdr-db05', 'hdr-db05', work_dir, python_path),
    Worker('hdr-db06', 'hdr-db06', work_dir, python_path),
    Worker('hdr-db07', 'hdr-db07', work_dir, python_path),
    Worker('hdr-db08', 'hdr-db08', work_dir, python_path),
    Worker('hdr-db09', 'hdr-db09', work_dir, python_path),
    Worker('hdr-db10', 'hdr-db10', work_dir, python_path),
    Worker('hdr-db11', 'hdr-db11', work_dir, python_path),
    Worker('hdr-db12', 'hdr-db12', work_dir, python_path),
]

###############################################################################
# tasks
#
# Each worker processes `tasks`.
# `tasks` defines jobs a worker should process.
######################################## #######################################
hostname = subprocess.check_output(['hostname']).decode().strip()
this_worker: Worker = {worker.hostname: worker for worker in workers}.get(hostname)  # type: ignore


@lru_cache(maxsize=None)
def cached_rerun(rerun_name: str):
    return Rerun(f'{this_worker.work_dir}/repo/{rerun_name}')


def tasks(env):
    rerun = cached_rerun(env.get('rerun'))
    return rerun.patches


###############################################################################
# mapper_wrapper
#
# mapper will be decorated with `mapper_wrapper`
###############################################################################
def mapper_wrapper(mapper: Callable[[Patch], Any]):
    def wrapper(patch: Patch):
        with patch.clear_cache():
            return mapper(patch)
    return wrapper


###############################################################################
# 
#
# lines below are executed in both master and workers,
# so we can put global settings here.
###############################################################################
def setup():
    import numpy
    numpy.seterr(all='ignore')


setup()
